% chktex-file 3
% chktex-file 8
% chktex-file 10
% chktex-file 13
% chktex-file 17
% chktex-file 24
% chktex-file 25
% chktex-file 36
% chktex-file 37

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Linear Least Squares}
% ref: https://en.wikipedia.org/wiki/Linear_least_squares

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Linear least squares (LLS) is a set of formulations for solving statistical problems involved in linear regression,
including variants for ordinary, weighted, and generalized residuals.

Consider the linear equation
\begin{equation}
    \mathbf{A} \mathbf{x} = \mathbf{b}
    \label{e:lls:leq}
\end{equation}
where $\mathbf{A} \in \mathbb{R}^{m \times n}$ and $\mathbf{b} \in \mathbb{R}^m$. When $m>n$,
$\mathbf{x} \in \mathbb{R}^n$ is the solution of
\begin{equation*}
    \underset{\mathbf{x} \in \mathbb{R}^n}{\text{minimize}} \left| \mathbf{A} \mathbf{x} - \mathbf{b} \right|^2
\end{equation*}
$\mathbf{x}$ can be computed by
\begin{equation*}
    \mathbf{A}^\top \mathbf{A} \mathbf{x}^* = \mathbf{A}^\top \mathbf{b}
\end{equation*}
\begin{equation}
    \mathbf{x}^* = (\mathbf{A}^\top \mathbf{A})^{-1} \mathbf{A}^\top \mathbf{b}
    \label{e:lls:sol}
\end{equation}
where $\mathbf{A}^\top$ denotes the transpose of $\mathbf{A}$ and $\mathbf{A} \mathbf{x}^*$ is the projection of
$\mathbf{b}$ in columnn space of $\mathbf{A}$.